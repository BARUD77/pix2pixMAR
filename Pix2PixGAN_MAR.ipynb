{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b54ae21-7c99-467c-a171-c46cf9c860ec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df03d30-e046-459f-b115-5ccc8566a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time\n",
    "from progress.bar import IncrementalBar\n",
    "\n",
    "from generator import UnetGenerator\n",
    "from discriminator import ConditionalDiscriminator\n",
    "from criterion import GeneratorLoss, DiscriminatorLoss\n",
    "from utils import Logger, initialize_weights\n",
    "from dataset import ArtifactDataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d304a2-a228-4ea9-9750-82474fbb9f0c",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea94f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining models!\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Pad((48, 48, 48, 48)),  # Add 24 pixels of padding to match 512x512 size\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize images (optional)\n",
    "])\n",
    "\n",
    "# Path to your .txt file and root directory\n",
    "txt_file = '/home/maya/train_640geo_dir.txt'  # Replace with actual path to your .txt file \n",
    "root_dir = '/home/maya/train_640reduced/'  # Replace with actual root directory\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ArtifactDataset(txt_file=txt_file, root_dir=root_dir, transform=transform)\n",
    "\n",
    "# Create the DataLoader with shuffling\n",
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# models\n",
    "print('Defining models!')\n",
    "generator = UnetGenerator().to(device)\n",
    "discriminator = ConditionalDiscriminator().to(device)\n",
    "\n",
    "#optimizers\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n",
    "# loss functions\n",
    "g_criterion = GeneratorLoss(alpha=100)\n",
    "d_criterion = DiscriminatorLoss()\n",
    "logger = Logger(filename='Metal_Artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ed1e25-74d5-4f4e-9487-c9e77f04401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Artifact Image Batch Shape: torch.Size([32, 1, 256, 256])\n",
      "Ground Truth Image Batch Shape: torch.Size([32, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the DataLoader to check the batches\n",
    "for i, (artifact_images, gt_images) in enumerate(dataloader):\n",
    "    print(f'Batch {i + 1}:')\n",
    "    print(f'Artifact Image Batch Shape: {artifact_images.shape}')\n",
    "    print(f'Ground Truth Image Batch Shape: {gt_images.shape}')\n",
    "    \n",
    "    # Stop after printing the first batch (optional)\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3de0c9-befe-4c05-85c3-b4ecf0bfcb2b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932cbab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m d_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# add batch losses\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m ge_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m g_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     35\u001b[0m de_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     36\u001b[0m bar\u001b[38;5;241m.\u001b[39mnext()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage in a training loop\n",
    "for epoch in range(100):\n",
    "    ge_loss = 0.\n",
    "    de_loss = 0.\n",
    "    start = time.time()\n",
    "    bar = IncrementalBar(f'[Epoch {epoch+1}/{100}]', max=len(dataloader))\n",
    "    for batch_idx, (x, real) in enumerate(dataloader):\n",
    "        # Each batch contains artifact-affected images (x)  and their corresponding clean images (real)\n",
    "        x=x.to(device)\n",
    "        real = real.to(device)\n",
    "\n",
    "        # generator's loss\n",
    "        fake = generator(x)\n",
    "        fake_pred = discriminator(fake, x)\n",
    "        g_loss = g_criterion(fake, real, fake_pred)\n",
    "        \n",
    "        # discriminator's loss \n",
    "        fake = generator(x).detach()\n",
    "        fake_pred = discriminator(fake, x)\n",
    "        real_pred = discriminator(real, x)\n",
    "        d_loss = d_criterion(fake_pred, real_pred)\n",
    "        \n",
    "        # Generator`s params update\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Discriminator`s params update\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # add batch losses\n",
    "        ge_loss += g_loss.item()\n",
    "        de_loss += d_loss.item()\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    # obtain per epoch losses\n",
    "    g_loss = ge_loss/len(dataloader)\n",
    "    d_loss = de_loss/len(dataloader)\n",
    "    # count timeframe\n",
    "    end = time.time()\n",
    "    tm = (end - start)\n",
    "    logger.add_scalar('generator_loss', g_loss, epoch+1)\n",
    "    logger.add_scalar('discriminator_loss', d_loss, epoch+1)\n",
    "    logger.save_weights(generator.state_dict(), 'generator')\n",
    "    logger.save_weights(discriminator.state_dict(), 'discriminator')\n",
    "    print(\"[Epoch %d/%d] [G loss: %.3f] [D loss: %.3f] ETA: %.3fs\" % (epoch+1, 100, g_loss, d_loss, tm))\n",
    "logger.close()\n",
    "print('End of training process!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6917f65-8c34-4f33-9e11-8f6e727f1335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorenv)",
   "language": "python",
   "name": "tensorenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
